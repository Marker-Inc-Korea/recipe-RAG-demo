# In this yaml, we do not use tree_summarize for accuracy
# And did not use monoT5, because it can take too long.
node_lines:
  - node_line_name: retrieve_node_line  # Arbitrary node line name
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [ retrieval_recall ]
        top_k: 3
        modules:
          - module_type: bm25
          - module_type: vectordb
            embedding_model: [ huggingface_baai_bge_small, huggingface_all_mpnet_base_v2 ]
          - module_type: hybrid_rrf
            target_modules: ('bm25', 'vectordb')
            rrf_k: [ 3, 5, 10 ]
          - module_type: hybrid_cc
            target_modules: ('bm25', 'vectordb')
            weights:
              - (0.5, 0.5)
              - (0.3, 0.7)
              - (0.7, 0.3)
  - node_line_name: post_retrieve_node_line
    nodes:
      - node_type: prompt_maker
        strategy:
          metrics: [ bleu, meteor, rouge, sem_score ]
          generator_modules:
            - module_type: llama_index_llm
              llm: vllm
              batch: 8
              model: mistralai/Mistral-7B-Instruct-v0.2
        modules:
          - module_type: fstring
            prompt:
              - "Answer to given questions with the following recipes: {retrieved_contents} \n\n Question: {query} \n\n Answer:"
              - "Recipes: {retrieved_contents} \n\n Question: {query} \n\n First, select the best recipe related to question. Next, answer the question using the recipe."
              - "Answer to given questions with the following recipes: {retrieved_contents} \n\n Question: {query} \n\n Answer the question. Be concise. Do not make up unknown information. Do not make up your own recipe. If you don't know about the question, please says you don't know."
      - node_type: generator
        strategy:
          metrics: [ bleu, meteor, rouge, sem_score ]
        modules:
          - module_type: llama_index_llm
            llm: vllm
            model: mistralai/Mistral-7B-Instruct-v0.2
            temperature: [ 0.1, 0.6, 1.2 ]
            batch: 8
